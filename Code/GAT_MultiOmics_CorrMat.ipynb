{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "JS7OBdFlHeDP",
   "metadata": {
    "id": "JS7OBdFlHeDP"
   },
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/avakanski/Graph_NNs_for_Multi_Omics_Integration/blob/main/Code/GAT_MultiOmics_CorrMat.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jsnebcpV8nRd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20352,
     "status": "ok",
     "timestamp": 1741374640539,
     "user": {
      "displayName": "Aleksandar Vakanski",
      "userId": "07675307153279708378"
     },
     "user_tz": 420
    },
    "id": "jsnebcpV8nRd",
    "outputId": "72f0bf5e-cc66-4652-9de2-e8a2613f2d7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TT1Kbn-J8qsE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3075,
     "status": "ok",
     "timestamp": 1741374643615,
     "user": {
      "displayName": "Aleksandar Vakanski",
      "userId": "07675307153279708378"
     },
     "user_tz": 420
    },
    "id": "TT1Kbn-J8qsE",
    "outputId": "e67ad081-30e9-4a78-abdc-73a0b258a8ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YB3AFUVB8v9G",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12585,
     "status": "ok",
     "timestamp": 1741374656202,
     "user": {
      "displayName": "Aleksandar Vakanski",
      "userId": "07675307153279708378"
     },
     "user_tz": 420
    },
    "id": "YB3AFUVB8v9G",
    "outputId": "496a8491-afb5-4e21-918a-b4f73d0e4ef8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# GAT using multi-omics data (mRNA, miRNA and DNA methylation) with correlation matrix graph structure (5 fold cross validation)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GATConv\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "from torch.nn import BatchNorm1d, LeakyReLU\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import datetime\n",
    "now = datetime.datetime.now\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3nAX0dR89yX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1465,
     "status": "ok",
     "timestamp": 1741374657668,
     "user": {
      "displayName": "Aleksandar Vakanski",
      "userId": "07675307153279708378"
     },
     "user_tz": 420
    },
    "id": "d3nAX0dR89yX",
    "outputId": "19fe06fa-60f5-4117-e2df-7b3de3f12ce9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-dbafd6daffc1>:23: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  edges = ppi_filtered[['stringId_A', 'stringId_B']].applymap(lambda x: protein_to_id[x])\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load the PPI data\n",
    "ppi_file_path = 'drive/My Drive/Projects/Gene_Expression_Project/PPI.csv'\n",
    "ppi_df = pd.read_csv(ppi_file_path)\n",
    "\n",
    "# Step 2: Concatenate 'stringId_A' and 'stringId_B' to calculate the number of connections (degree)\n",
    "all_proteins = pd.concat([ppi_df['stringId_A'], ppi_df['stringId_B']])\n",
    "\n",
    "# Step 3: Count the number of connections for each protein\n",
    "protein_connections = all_proteins.value_counts()\n",
    "\n",
    "# Step 4: Define a degree threshold to select only highly connected proteins (e.g., 200 or more connections)\n",
    "degree_threshold = 200\n",
    "high_degree_proteins = protein_connections[protein_connections >= degree_threshold].index\n",
    "\n",
    "# Step 5: Filter the PPI data to include only edges where both proteins have a high number of connections\n",
    "ppi_filtered = ppi_df[ppi_df['stringId_A'].isin(high_degree_proteins) & ppi_df['stringId_B'].isin(high_degree_proteins)]\n",
    "\n",
    "# Step 6: Map the high-degree proteins to unique node IDs\n",
    "proteins = pd.concat([ppi_filtered['stringId_A'], ppi_filtered['stringId_B']]).unique()\n",
    "protein_to_id = {protein: idx for idx, protein in enumerate(proteins)}\n",
    "\n",
    "# Step 7: Create edge index (this will be the input for GAT)\n",
    "edges = ppi_filtered[['stringId_A', 'stringId_B']].applymap(lambda x: protein_to_id[x])\n",
    "edge_index = torch.tensor(edges.values.T, dtype=torch.long).to(device)  # Move edge index to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Z-l6Xit-890Y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13768,
     "status": "ok",
     "timestamp": 1741374671438,
     "user": {
      "displayName": "Aleksandar Vakanski",
      "userId": "07675307153279708378"
     },
     "user_tz": 420
    },
    "id": "Z-l6Xit-890Y",
    "outputId": "780ab0af-6e3f-4a10-dbfc-80c18906f245"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-03-07 19:10:57--  https://www.webpages.uidaho.edu/vakanski/Codes_Data/mRNA_miRNA_Meth_integrated.csv\n",
      "Resolving www.webpages.uidaho.edu (www.webpages.uidaho.edu)... 129.101.105.230\n",
      "Connecting to www.webpages.uidaho.edu (www.webpages.uidaho.edu)|129.101.105.230|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 123599052 (118M) [application/octet-stream]\n",
      "Saving to: ‘mRNA_miRNA_Meth_integrated.csv’\n",
      "\n",
      "mRNA_miRNA_Meth_int 100%[===================>] 117.87M  17.0MB/s    in 9.5s    \n",
      "\n",
      "2025-03-07 19:11:08 (12.4 MB/s) - ‘mRNA_miRNA_Meth_integrated.csv’ saved [123599052/123599052]\n",
      "\n",
      "Number of classes: 32\n",
      "Number of samples: 8464\n",
      "Number of Features: 2793\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Load and preprocess the multi-omics data\n",
    "!wget https://www.idahofallshighered.org/vakanski/Codes_Data/mRNA_miRNA_Meth_integrated.csv\n",
    "file_path = 'mRNA_miRNA_Meth_integrated.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "Y = df.iloc[:, -1].copy()\n",
    "\n",
    "# Remove non-numeric columns\n",
    "df = df.select_dtypes(include=[np.number])\n",
    "X = df.values\n",
    "\n",
    "num_classes = len(set(Y))\n",
    "print(\"Number of classes:\", num_classes)\n",
    "num_samples = X.shape[0]\n",
    "print(\"Number of samples:\", num_samples)\n",
    "num_Features = X.shape[1]\n",
    "print(\"Number of Features:\", num_Features)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "Y = label_encoder.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XiCishdy9HqP",
   "metadata": {
    "id": "XiCishdy9HqP"
   },
   "outputs": [],
   "source": [
    "# Step 9: Define the GAT model\n",
    "class GAT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GAT, self).__init__()\n",
    "        self.conv1 = GATConv(X.shape[1], 1024, heads=8)\n",
    "        self.bn1 = BatchNorm1d(1024 * 8)\n",
    "        self.relu1 = LeakyReLU()\n",
    "        self.conv2 = GATConv(1024 * 8, 512, heads=4)\n",
    "        self.bn2 = BatchNorm1d(512 * 4)\n",
    "        self.relu2 = LeakyReLU()\n",
    "        self.conv3 = GATConv(512 * 4, 256, heads=2)\n",
    "        self.bn3 = BatchNorm1d(256 * 2)\n",
    "        self.relu3 = LeakyReLU()\n",
    "        self.conv4 = GATConv(256 * 2, 32, heads=1)\n",
    "        self.bn4 = BatchNorm1d(32)\n",
    "        self.relu4 = LeakyReLU()\n",
    "        self.dropout = nn.Dropout(0.3)  # Apply the specified dropout rate\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.conv4(x, edge_index)\n",
    "        x = self.bn4(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.dropout(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "# Step 10: Set up K-fold cross-validation\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "\n",
    "# Initialize lists to store metrics for each fold\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "accuracy_scores = []\n",
    "F1Measure = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3969d149",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 259067,
     "status": "ok",
     "timestamp": 1741374930515,
     "user": {
      "displayName": "Aleksandar Vakanski",
      "userId": "07675307153279708378"
     },
     "user_tz": 420
    },
    "id": "3969d149",
    "outputId": "5a96420c-a2a4-4f6b-a3a4-ebba19037f4b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-ce55b38050fd>:20: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  edge_index_train = torch.tensor([src_train, dst_train], dtype=torch.long).to(device)\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:04:19.037287\n"
     ]
    }
   ],
   "source": [
    "# Step 11: Training and Evaluation\n",
    "t = now()\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "    X_train = torch.FloatTensor(X_train).to(device)\n",
    "    y_train = torch.LongTensor(y_train).to(device)\n",
    "    X_test = torch.FloatTensor(X_test).to(device)\n",
    "    y_test = torch.LongTensor(y_test).to(device)\n",
    "\n",
    "    # Calculate the correlation matrix and convert it to an edge index\n",
    "    correlation_matrix_train = np.corrcoef(X_train.cpu(), rowvar=True)\n",
    "    correlation_matrix_test = np.corrcoef(X_test.cpu(), rowvar=True)\n",
    "\n",
    "    # Create edge indices based on a correlation threshold\n",
    "    src_train, dst_train = np.where(correlation_matrix_train > 0.9)\n",
    "    src_test, dst_test = np.where(correlation_matrix_test > 0.9)\n",
    "\n",
    "    edge_index_train = torch.tensor([src_train, dst_train], dtype=torch.long).to(device)\n",
    "    edge_index_test = torch.tensor([src_test, dst_test], dtype=torch.long).to(device)\n",
    "\n",
    "    # Create PyTorch Geometric data objects\n",
    "    train_data = Data(x=X_train, edge_index=edge_index_train).to(device)\n",
    "    test_data = Data(x=X_test, edge_index=edge_index_test).to(device)\n",
    "\n",
    "    # Create the GAT model with tuned parameters\n",
    "    model = GAT().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)  # Set the specified learning rate\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    num_epochs = 100\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(train_data)\n",
    "        loss = criterion(out, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            logits = model(test_data)\n",
    "            pred = torch.argmax(logits, dim=1)\n",
    "            acc = accuracy_score(y_test.cpu().numpy(), pred.cpu().numpy())\n",
    "            # print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}, Validation Accuracy: {acc:.4f}')\n",
    "\n",
    "    # Testing\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(test_data)\n",
    "        pred = torch.argmax(logits, dim=1)\n",
    "        test_acc = accuracy_score(y_test.cpu().numpy(), pred.cpu().numpy())\n",
    "        precision = precision_score(y_test.cpu().numpy(), pred.cpu().numpy(), average='macro', zero_division=1)\n",
    "        recall = recall_score(y_test.cpu().numpy(), pred.cpu().numpy(), average='macro')\n",
    "        f1 = f1_score(y_test.cpu().numpy(), pred.cpu().numpy(), average='macro')\n",
    "\n",
    "        accuracy_scores.append(test_acc)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        F1Measure.append(f1)\n",
    "print('Training time: %s' % (now() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "D4UiJ4EF9WD7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1741374930525,
     "user": {
      "displayName": "Aleksandar Vakanski",
      "userId": "07675307153279708378"
     },
     "user_tz": 420
    },
    "id": "D4UiJ4EF9WD7",
    "outputId": "5f359a1d-c0c1-4495-ad89-d4e9806c0b87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy = 0.958530327213013\n",
      "Accuracy std sev = 0.0024311323943563123\n",
      "Average precision = 0.9333677756849544\n",
      "Precision std sev = 0.020768593440016647\n",
      "Average recall = 0.9364388490361402\n",
      "Recall std sev = 0.015947474761482523\n",
      "Average F1 score = 0.9335732312352951\n",
      "F1 std dev = 0.01782216803131316\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average metrics across all folds\n",
    "average_accuracy = np.mean(accuracy_scores)\n",
    "average_precision = np.mean(precision_scores)\n",
    "average_recall = np.mean(recall_scores)\n",
    "average_f1 = np.mean(F1Measure)\n",
    "\n",
    "print(\"Average accuracy =\", average_accuracy)\n",
    "print(\"Accuracy std sev =\", np.std(accuracy_scores))\n",
    "print(\"Average precision =\", average_precision)\n",
    "print(\"Precision std sev =\", np.std(precision_scores))\n",
    "print(\"Average recall =\", average_recall)\n",
    "print(\"Recall std sev =\", np.std(recall_scores))\n",
    "print(\"Average F1 score =\", average_f1)\n",
    "print(\"F1 std dev =\", np.std(F1Measure))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

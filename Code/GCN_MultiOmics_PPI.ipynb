{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "yBqrktNhIcRd",
   "metadata": {
    "id": "yBqrktNhIcRd"
   },
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/avakanski/Graph_NNs_for_Multi_Omics_Integration/blob/main/Code/GCN_MultiOmics_PPI.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cCS261zhs9DN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24913,
     "status": "ok",
     "timestamp": 1741371508346,
     "user": {
      "displayName": "Aleksandar Vakanski",
      "userId": "07675307153279708378"
     },
     "user_tz": 420
    },
    "id": "cCS261zhs9DN",
    "outputId": "7f2f9b8b-e72a-4fd1-8d54-0e94c5147694"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eIydkWXs-Ri",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3271,
     "status": "ok",
     "timestamp": 1741371511628,
     "user": {
      "displayName": "Aleksandar Vakanski",
      "userId": "07675307153279708378"
     },
     "user_tz": 420
    },
    "id": "4eIydkWXs-Ri",
    "outputId": "442a0616-a199-47b0-ccc0-f33e814b35b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/1.1 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q torch_geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lnQaPpr_tE57",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12059,
     "status": "ok",
     "timestamp": 1741371523689,
     "user": {
      "displayName": "Aleksandar Vakanski",
      "userId": "07675307153279708378"
     },
     "user_tz": 420
    },
    "id": "lnQaPpr_tE57",
    "outputId": "fdf1f8f4-bb1f-4720-de8a-377fedf7f8ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# GCN using multi-omics data (mRNA, miRNA and DNA methylation) with PPI graph structure (5 fold cross validation))\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GraphConv  # Replace GATConv with GraphConv\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
    "from torch.nn import BatchNorm1d, LeakyReLU\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import datetime\n",
    "now = datetime.datetime.now\n",
    "\n",
    "# Check if GPU is available and set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ykm0t0OstE-3",
   "metadata": {
    "id": "ykm0t0OstE-3"
   },
   "outputs": [],
   "source": [
    "# Step 1: Load the PPI data\n",
    "ppi_file_path = 'drive/My Drive/Projects/Gene_Expression_Project/PPI.csv'\n",
    "ppi_df = pd.read_csv(ppi_file_path)\n",
    "\n",
    "# Step 2: Concatenate 'stringId_A' and 'stringId_B' to calculate the number of connections (degree)\n",
    "all_proteins = pd.concat([ppi_df['stringId_A'], ppi_df['stringId_B']])\n",
    "\n",
    "# Step 3: Count the number of connections for each protein\n",
    "protein_connections = all_proteins.value_counts()\n",
    "\n",
    "# Step 4: Define a degree threshold to select only highly connected proteins (e.g., 5 or more connections)\n",
    "degree_threshold = 200\n",
    "high_degree_proteins = protein_connections[protein_connections >= degree_threshold].index\n",
    "\n",
    "# Step 5: Filter the PPI data to include only edges where both proteins have a high number of connections\n",
    "ppi_filtered = ppi_df[ppi_df['stringId_A'].isin(high_degree_proteins) & ppi_df['stringId_B'].isin(high_degree_proteins)]\n",
    "\n",
    "# Step 6: Map the high-degree proteins to unique node IDs\n",
    "proteins = pd.concat([ppi_filtered['stringId_A'], ppi_filtered['stringId_B']]).unique()\n",
    "protein_to_id = {protein: idx for idx, protein in enumerate(proteins)}\n",
    "\n",
    "# Step 7: Create edge index (this will be the input for GCN)\n",
    "edges = ppi_filtered[['stringId_A', 'stringId_B']].map(lambda x: protein_to_id[x])\n",
    "edge_index = torch.tensor(edges.values.T, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sQsfLKyjtfLf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12329,
     "status": "ok",
     "timestamp": 1741371537092,
     "user": {
      "displayName": "Aleksandar Vakanski",
      "userId": "07675307153279708378"
     },
     "user_tz": 420
    },
    "id": "sQsfLKyjtfLf",
    "outputId": "5adff16c-c310-455e-bb01-513fef675912"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-03-07 18:18:05--  https://www.webpages.uidaho.edu/vakanski/Codes_Data/mRNA_miRNA_Meth_integrated.csv\n",
      "Resolving www.webpages.uidaho.edu (www.webpages.uidaho.edu)... 129.101.105.230\n",
      "Connecting to www.webpages.uidaho.edu (www.webpages.uidaho.edu)|129.101.105.230|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 123599052 (118M) [application/octet-stream]\n",
      "Saving to: ‘mRNA_miRNA_Meth_integrated.csv’\n",
      "\n",
      "mRNA_miRNA_Meth_int 100%[===================>] 117.87M  15.2MB/s    in 8.4s    \n",
      "\n",
      "2025-03-07 18:18:14 (14.1 MB/s) - ‘mRNA_miRNA_Meth_integrated.csv’ saved [123599052/123599052]\n",
      "\n",
      "Number of classes: 32\n",
      "Number of samples: 8464\n",
      "Number of Features: 2793\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Load and preprocess the multi-omics data\n",
    "!wget https://www.idahofallshighered.org/vakanski/Codes_Data/mRNA_miRNA_Meth_integrated.csv\n",
    "file_path = 'mRNA_miRNA_Meth_integrated.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "Y = df.iloc[:, -1].copy()\n",
    "\n",
    "# Remove non-numeric columns\n",
    "df = df.select_dtypes(include=[np.number])\n",
    "X = df.values\n",
    "\n",
    "num_classes = len(set(Y))\n",
    "print(\"Number of classes:\", num_classes)\n",
    "num_samples = X.shape[0]\n",
    "print(\"Number of samples:\", num_samples)\n",
    "num_Features = X.shape[1]\n",
    "print(\"Number of Features:\", num_Features)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "Y = label_encoder.fit_transform(Y)\n",
    "\n",
    "# Step 9: Create PyTorch Geometric data object using the edge_index from the filtered PPI network\n",
    "data = Data(x=torch.tensor(X, dtype=torch.float), edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "H1VyWTznvNM4",
   "metadata": {
    "id": "H1VyWTznvNM4"
   },
   "outputs": [],
   "source": [
    "# Step 10: Define the GCN model with adjusted parameters\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_feats, num_classes, num_layers=2, dropout=0.5):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv_layers = nn.ModuleList([GraphConv(in_feats, hidden_feats)])\n",
    "        self.conv_layers.extend([GraphConv(hidden_feats, hidden_feats) for _ in range(num_layers - 1)])\n",
    "        self.final_conv = GraphConv(hidden_feats, num_classes)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        for conv in self.conv_layers:\n",
    "            x = torch.relu(conv(x, edge_index))\n",
    "            x = self.dropout(x)\n",
    "        x = self.final_conv(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)  # Use softmax for classification\n",
    "\n",
    "# Step 11: Set up K-fold cross-validation\n",
    "k = 5\n",
    "kf = KFold(n_splits=k, shuffle=True)\n",
    "\n",
    "# Initialize lists to store metrics for each fold\n",
    "precision_scores = []\n",
    "recall_scores = []\n",
    "accuracy_scores = []\n",
    "F1Measure = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8589ec3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 531905,
     "status": "ok",
     "timestamp": 1741372075856,
     "user": {
      "displayName": "Aleksandar Vakanski",
      "userId": "07675307153279708378"
     },
     "user_tz": 420
    },
    "id": "d8589ec3",
    "outputId": "6ca47229-dc8c-4e4a-90e6-294fc91f8989"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 0:08:51.872442\n"
     ]
    }
   ],
   "source": [
    "# Step 12: Training and Evaluation\n",
    "t = now()\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    X_train = torch.FloatTensor(X_train)\n",
    "    y_train = torch.LongTensor(y_train)\n",
    "    X_test = torch.FloatTensor(X_test)\n",
    "    y_test = torch.LongTensor(y_test)\n",
    "\n",
    "    # Create train/test data using the same PPI edge_index\n",
    "    train_data = Data(x=X_train, edge_index=edge_index)\n",
    "    test_data = Data(x=X_test, edge_index=edge_index)\n",
    "\n",
    "    # Create the GCN model\n",
    "    model = GCN(in_feats=X.shape[1], hidden_feats=1024, num_classes=len(set(Y)), num_layers=2, dropout=0.5)\n",
    "\n",
    "    # Set optimizer with the best parameters\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0)\n",
    "    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=10)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    num_epochs = 100\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(train_data)\n",
    "        loss = criterion(out, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            logits = model(test_data)\n",
    "            pred = torch.argmax(logits, dim=1)\n",
    "            acc = accuracy_score(y_test.numpy(), pred.numpy())\n",
    "            # print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}, Validation Accuracy: {acc:.4f}')\n",
    "            scheduler.step(acc)\n",
    "\n",
    "    # Testing\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(test_data)\n",
    "        pred = torch.argmax(logits, dim=1)\n",
    "        test_acc = accuracy_score(y_test.numpy(), pred.numpy())\n",
    "        precision = precision_score(y_test.numpy(), pred.numpy(), average='macro', zero_division=1)\n",
    "        recall = recall_score(y_test.numpy(), pred.numpy(), average='macro')\n",
    "        f1 = f1_score(y_test.numpy(), pred.numpy(), average='macro')\n",
    "\n",
    "        accuracy_scores.append(test_acc)\n",
    "        precision_scores.append(precision)\n",
    "        recall_scores.append(recall)\n",
    "        F1Measure.append(f1)\n",
    "\n",
    "print('Training time: %s' % (now() - t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eENGPiEtp1s",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1741372075875,
     "user": {
      "displayName": "Aleksandar Vakanski",
      "userId": "07675307153279708378"
     },
     "user_tz": 420
    },
    "id": "9eENGPiEtp1s",
    "outputId": "880e6064-909e-4ce8-d8a7-e29680ef7913"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy = 0.949669896486576\n",
      "Accuracy std dev = 0.003422787341768131\n",
      "Average precision = 0.9394252200351356\n",
      "Precision std dev = 0.007046327150337359\n",
      "Average recall = 0.9209217476478753\n",
      "Recall std dev = 0.01593551563848332\n",
      "Average F1 score = 0.9211831326351975\n",
      "F1 std dev = 0.013584381909040983\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average metrics across all folds\n",
    "average_accuracy = np.mean(accuracy_scores)\n",
    "average_precision = np.mean(precision_scores)\n",
    "average_recall = np.mean(recall_scores)\n",
    "average_f1 = np.mean(F1Measure)\n",
    "\n",
    "print(\"Average accuracy =\", average_accuracy)\n",
    "print(\"Accuracy std dev =\", np.std(accuracy_scores))\n",
    "print(\"Average precision =\", average_precision)\n",
    "print(\"Precision std dev =\", np.std(precision_scores))\n",
    "print(\"Average recall =\", average_recall)\n",
    "print(\"Recall std dev =\", np.std(recall_scores))\n",
    "print(\"Average F1 score =\", average_f1)\n",
    "print(\"F1 std dev =\", np.std(F1Measure))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{"cells":[{"cell_type":"markdown","source":["<a target=\"_blank\" href=\"https://colab.research.google.com/github/avakanski/Graph_NNs_for_Multi_Omics_Integration/blob/main/Code/GCN_MultiOmics_PPI.ipynb\">\n","  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n","</a>"],"metadata":{"id":"yBqrktNhIcRd"},"id":"yBqrktNhIcRd"},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cCS261zhs9DN","executionInfo":{"status":"ok","timestamp":1741371508346,"user_tz":420,"elapsed":24913,"user":{"displayName":"Aleksandar Vakanski","userId":"07675307153279708378"}},"outputId":"7f2f9b8b-e72a-4fd1-8d54-0e94c5147694"},"id":"cCS261zhs9DN","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install -q torch_geometric"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4eIydkWXs-Ri","executionInfo":{"status":"ok","timestamp":1741371511628,"user_tz":420,"elapsed":3271,"user":{"displayName":"Aleksandar Vakanski","userId":"07675307153279708378"}},"outputId":"442a0616-a199-47b0-ccc0-f33e814b35b8"},"id":"4eIydkWXs-Ri","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/1.1 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["# GCN using multi-omics data (mRNA, miRNA and DNA methylation) with PPI graph structure (5 fold cross validation))\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch_geometric.data import Data\n","from torch_geometric.nn import GraphConv  # Replace GATConv with GraphConv\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n","from torch.nn import BatchNorm1d, LeakyReLU\n","import torch.nn.functional as F\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","import datetime\n","now = datetime.datetime.now\n","\n","# Check if GPU is available and set device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Using device: {device}\")"],"metadata":{"id":"lnQaPpr_tE57","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741371523689,"user_tz":420,"elapsed":12059,"user":{"displayName":"Aleksandar Vakanski","userId":"07675307153279708378"}},"outputId":"fdf1f8f4-bb1f-4720-de8a-377fedf7f8ad"},"id":"lnQaPpr_tE57","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}]},{"cell_type":"code","source":["# Step 1: Load the PPI data\n","ppi_file_path = 'drive/My Drive/Projects/Gene_Expression_Project/PPI.csv'\n","ppi_df = pd.read_csv(ppi_file_path)\n","\n","# Step 2: Concatenate 'stringId_A' and 'stringId_B' to calculate the number of connections (degree)\n","all_proteins = pd.concat([ppi_df['stringId_A'], ppi_df['stringId_B']])\n","\n","# Step 3: Count the number of connections for each protein\n","protein_connections = all_proteins.value_counts()\n","\n","# Step 4: Define a degree threshold to select only highly connected proteins (e.g., 5 or more connections)\n","degree_threshold = 200\n","high_degree_proteins = protein_connections[protein_connections >= degree_threshold].index\n","\n","# Step 5: Filter the PPI data to include only edges where both proteins have a high number of connections\n","ppi_filtered = ppi_df[ppi_df['stringId_A'].isin(high_degree_proteins) & ppi_df['stringId_B'].isin(high_degree_proteins)]\n","\n","# Step 6: Map the high-degree proteins to unique node IDs\n","proteins = pd.concat([ppi_filtered['stringId_A'], ppi_filtered['stringId_B']]).unique()\n","protein_to_id = {protein: idx for idx, protein in enumerate(proteins)}\n","\n","# Step 7: Create edge index (this will be the input for GCN)\n","edges = ppi_filtered[['stringId_A', 'stringId_B']].map(lambda x: protein_to_id[x])\n","edge_index = torch.tensor(edges.values.T, dtype=torch.long)"],"metadata":{"id":"ykm0t0OstE-3"},"id":"ykm0t0OstE-3","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 8: Load and preprocess the multi-omics data\n","!wget https://www.webpages.uidaho.edu/vakanski/Codes_Data/mRNA_miRNA_Meth_integrated.csv\n","file_path = 'mRNA_miRNA_Meth_integrated.csv'\n","df = pd.read_csv(file_path)\n","df.drop(df.columns[0], axis=1, inplace=True)\n","Y = df.iloc[:, -1].copy()\n","\n","# Remove non-numeric columns\n","df = df.select_dtypes(include=[np.number])\n","X = df.values\n","\n","num_classes = len(set(Y))\n","print(\"Number of classes:\", num_classes)\n","num_samples = X.shape[0]\n","print(\"Number of samples:\", num_samples)\n","num_Features = X.shape[1]\n","print(\"Number of Features:\", num_Features)\n","\n","# Standardize the features\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","# Encode labels\n","label_encoder = LabelEncoder()\n","Y = label_encoder.fit_transform(Y)\n","\n","# Step 9: Create PyTorch Geometric data object using the edge_index from the filtered PPI network\n","data = Data(x=torch.tensor(X, dtype=torch.float), edge_index=edge_index)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sQsfLKyjtfLf","executionInfo":{"status":"ok","timestamp":1741371537092,"user_tz":420,"elapsed":12329,"user":{"displayName":"Aleksandar Vakanski","userId":"07675307153279708378"}},"outputId":"5adff16c-c310-455e-bb01-513fef675912"},"id":"sQsfLKyjtfLf","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-03-07 18:18:05--  https://www.webpages.uidaho.edu/vakanski/Codes_Data/mRNA_miRNA_Meth_integrated.csv\n","Resolving www.webpages.uidaho.edu (www.webpages.uidaho.edu)... 129.101.105.230\n","Connecting to www.webpages.uidaho.edu (www.webpages.uidaho.edu)|129.101.105.230|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 123599052 (118M) [application/octet-stream]\n","Saving to: ‘mRNA_miRNA_Meth_integrated.csv’\n","\n","mRNA_miRNA_Meth_int 100%[===================>] 117.87M  15.2MB/s    in 8.4s    \n","\n","2025-03-07 18:18:14 (14.1 MB/s) - ‘mRNA_miRNA_Meth_integrated.csv’ saved [123599052/123599052]\n","\n","Number of classes: 32\n","Number of samples: 8464\n","Number of Features: 2793\n"]}]},{"cell_type":"code","source":["# Step 10: Define the GCN model with adjusted parameters\n","class GCN(nn.Module):\n","    def __init__(self, in_feats, hidden_feats, num_classes, num_layers=2, dropout=0.5):\n","        super(GCN, self).__init__()\n","        self.conv_layers = nn.ModuleList([GraphConv(in_feats, hidden_feats)])\n","        self.conv_layers.extend([GraphConv(hidden_feats, hidden_feats) for _ in range(num_layers - 1)])\n","        self.final_conv = GraphConv(hidden_feats, num_classes)\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        for conv in self.conv_layers:\n","            x = torch.relu(conv(x, edge_index))\n","            x = self.dropout(x)\n","        x = self.final_conv(x, edge_index)\n","        return F.log_softmax(x, dim=1)  # Use softmax for classification\n","\n","# Step 11: Set up K-fold cross-validation\n","k = 5\n","kf = KFold(n_splits=k, shuffle=True)\n","\n","# Initialize lists to store metrics for each fold\n","precision_scores = []\n","recall_scores = []\n","accuracy_scores = []\n","F1Measure = []"],"metadata":{"id":"H1VyWTznvNM4"},"id":"H1VyWTznvNM4","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"d8589ec3","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d8589ec3","executionInfo":{"status":"ok","timestamp":1741372075856,"user_tz":420,"elapsed":531905,"user":{"displayName":"Aleksandar Vakanski","userId":"07675307153279708378"}},"outputId":"6ca47229-dc8c-4e4a-90e6-294fc91f8989"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training time: 0:08:51.872442\n"]}],"source":["# Step 12: Training and Evaluation\n","t = now()\n","for train_index, test_index in kf.split(X):\n","    # Split the data into training and testing sets\n","    X_train, X_test = X[train_index], X[test_index]\n","    y_train, y_test = Y[train_index], Y[test_index]\n","\n","    # Convert to PyTorch tensors\n","    X_train = torch.FloatTensor(X_train)\n","    y_train = torch.LongTensor(y_train)\n","    X_test = torch.FloatTensor(X_test)\n","    y_test = torch.LongTensor(y_test)\n","\n","    # Create train/test data using the same PPI edge_index\n","    train_data = Data(x=X_train, edge_index=edge_index)\n","    test_data = Data(x=X_test, edge_index=edge_index)\n","\n","    # Create the GCN model\n","    model = GCN(in_feats=X.shape[1], hidden_feats=1024, num_classes=len(set(Y)), num_layers=2, dropout=0.5)\n","\n","    # Set optimizer with the best parameters\n","    optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0)\n","    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=10)\n","    criterion = nn.NLLLoss()\n","\n","    num_epochs = 100\n","    for epoch in range(num_epochs):\n","        model.train()\n","        optimizer.zero_grad()\n","        out = model(train_data)\n","        loss = criterion(out, y_train)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Validation\n","        model.eval()\n","        with torch.no_grad():\n","            logits = model(test_data)\n","            pred = torch.argmax(logits, dim=1)\n","            acc = accuracy_score(y_test.numpy(), pred.numpy())\n","            # print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}, Validation Accuracy: {acc:.4f}')\n","            scheduler.step(acc)\n","\n","    # Testing\n","    model.eval()\n","    with torch.no_grad():\n","        logits = model(test_data)\n","        pred = torch.argmax(logits, dim=1)\n","        test_acc = accuracy_score(y_test.numpy(), pred.numpy())\n","        precision = precision_score(y_test.numpy(), pred.numpy(), average='macro', zero_division=1)\n","        recall = recall_score(y_test.numpy(), pred.numpy(), average='macro')\n","        f1 = f1_score(y_test.numpy(), pred.numpy(), average='macro')\n","\n","        accuracy_scores.append(test_acc)\n","        precision_scores.append(precision)\n","        recall_scores.append(recall)\n","        F1Measure.append(f1)\n","\n","print('Training time: %s' % (now() - t))"]},{"cell_type":"code","source":["# Calculate the average metrics across all folds\n","average_accuracy = np.mean(accuracy_scores)\n","average_precision = np.mean(precision_scores)\n","average_recall = np.mean(recall_scores)\n","average_f1 = np.mean(F1Measure)\n","\n","print(\"Average accuracy =\", average_accuracy)\n","print(\"Accuracy std dev =\", np.std(accuracy_scores))\n","print(\"Average precision =\", average_precision)\n","print(\"Precision std dev =\", np.std(precision_scores))\n","print(\"Average recall =\", average_recall)\n","print(\"Recall std dev =\", np.std(recall_scores))\n","print(\"Average F1 score =\", average_f1)\n","print(\"F1 std dev =\", np.std(F1Measure))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9eENGPiEtp1s","executionInfo":{"status":"ok","timestamp":1741372075875,"user_tz":420,"elapsed":16,"user":{"displayName":"Aleksandar Vakanski","userId":"07675307153279708378"}},"outputId":"880e6064-909e-4ce8-d8a7-e29680ef7913"},"id":"9eENGPiEtp1s","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average accuracy = 0.949669896486576\n","Accuracy std dev = 0.003422787341768131\n","Average precision = 0.9394252200351356\n","Precision std dev = 0.007046327150337359\n","Average recall = 0.9209217476478753\n","Recall std dev = 0.01593551563848332\n","Average F1 score = 0.9211831326351975\n","F1 std dev = 0.013584381909040983\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}
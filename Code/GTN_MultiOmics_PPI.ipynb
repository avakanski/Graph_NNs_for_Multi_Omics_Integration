{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"36uvxgtPcRlS","executionInfo":{"status":"ok","timestamp":1741373320538,"user_tz":420,"elapsed":25658,"user":{"displayName":"Aleksandar Vakanski","userId":"07675307153279708378"}},"outputId":"6702d019-3f42-40d3-f7ec-1bdd6cacaa32"},"id":"36uvxgtPcRlS","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["!pip install -q torch_geometric"],"metadata":{"id":"RKxbDYxUcUYy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741373324332,"user_tz":420,"elapsed":3790,"user":{"displayName":"Aleksandar Vakanski","userId":"07675307153279708378"}},"outputId":"0ff57fbf-5c59-49dd-8aa8-9efb06a2ba74"},"id":"RKxbDYxUcUYy","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["# GTN using multi-omics data (mRNA, miRNA and DNA methylation) with PPI graph structure (5 fold cross validation)\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch_geometric.data import Data\n","from torch_geometric.nn import TransformerConv\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n","import torch.nn.functional as F\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","import datetime\n","now = datetime.datetime.now\n","\n","# Check if GPU is available and set device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(f\"Using device: {device}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7qMf4PWEciul","executionInfo":{"status":"ok","timestamp":1741373338052,"user_tz":420,"elapsed":13722,"user":{"displayName":"Aleksandar Vakanski","userId":"07675307153279708378"}},"outputId":"73e69ac9-4412-4159-ef05-63bf8dc435f0"},"id":"7qMf4PWEciul","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cuda\n"]}]},{"cell_type":"code","source":["# Step 1: Load the PPI data\n","ppi_file_path = 'drive/My Drive/Projects/Gene_Expression_Project/PPI.csv'\n","ppi_df = pd.read_csv(ppi_file_path)\n","\n","# Step 2: Concatenate 'stringId_A' and 'stringId_B' to calculate the number of connections (degree)\n","all_proteins = pd.concat([ppi_df['stringId_A'], ppi_df['stringId_B']])\n","\n","# Step 3: Count the number of connections for each protein\n","protein_connections = all_proteins.value_counts()\n","\n","# Step 4: Define a degree threshold to select only highly connected proteins (e.g., 200 or more connections)\n","degree_threshold = 200\n","high_degree_proteins = protein_connections[protein_connections >= degree_threshold].index\n","\n","# Step 5: Filter the PPI data to include only edges where both proteins have a high number of connections\n","ppi_filtered = ppi_df[\n","    ppi_df['stringId_A'].isin(high_degree_proteins) &\n","    ppi_df['stringId_B'].isin(high_degree_proteins)\n","]\n","\n","# Step 6: Map the high-degree proteins to unique node IDs\n","proteins = pd.concat([ppi_filtered['stringId_A'], ppi_filtered['stringId_B']]).unique()\n","protein_to_id = {protein: idx for idx, protein in enumerate(proteins)}\n","\n","# Step 7: Create edge index (this will be the input for GTN)\n","edges = ppi_filtered[['stringId_A', 'stringId_B']].map(lambda x: protein_to_id[x])\n","edge_index = torch.tensor(edges.values.T, dtype=torch.long).to(device)"],"metadata":{"id":"oUA1r1fzco-L"},"id":"oUA1r1fzco-L","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 8: Load and preprocess the multi-omics data\n","!wget https://www.webpages.uidaho.edu/vakanski/Codes_Data/mRNA_miRNA_Meth_integrated.csv\n","file_path = 'mRNA_miRNA_Meth_integrated.csv'\n","df = pd.read_csv(file_path)\n","df.drop(df.columns[0], axis=1, inplace=True)\n","Y = df.iloc[:, -1].copy()\n","\n","# Remove non-numeric columns\n","df = df.select_dtypes(include=[np.number])\n","X = df.values\n","\n","num_classes = len(set(Y))\n","print(\"Number of classes:\", num_classes)\n","num_samples = X.shape[0]\n","print(\"Number of samples:\", num_samples)\n","num_Features = X.shape[1]\n","print(\"Number of Features:\", num_Features)\n","\n","# Standardize the features\n","scaler = StandardScaler()\n","X = scaler.fit_transform(X)\n","\n","# Encode labels\n","label_encoder = LabelEncoder()\n","Y = label_encoder.fit_transform(Y)\n","\n","# Convert data to PyTorch tensors and move to device\n","X = torch.tensor(X, dtype=torch.float).to(device)\n","Y = torch.tensor(Y, dtype=torch.long).to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s-FXwJg3eY2Z","executionInfo":{"status":"ok","timestamp":1741373346741,"user_tz":420,"elapsed":7874,"user":{"displayName":"Aleksandar Vakanski","userId":"07675307153279708378"}},"outputId":"0aa44284-5dab-497e-e5e2-ed065c493bc4"},"id":"s-FXwJg3eY2Z","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2025-03-07 18:48:58--  https://www.webpages.uidaho.edu/vakanski/Codes_Data/mRNA_miRNA_Meth_integrated.csv\n","Resolving www.webpages.uidaho.edu (www.webpages.uidaho.edu)... 129.101.105.230\n","Connecting to www.webpages.uidaho.edu (www.webpages.uidaho.edu)|129.101.105.230|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 123599052 (118M) [application/octet-stream]\n","Saving to: ‘mRNA_miRNA_Meth_integrated.csv’\n","\n","mRNA_miRNA_Meth_int 100%[===================>] 117.87M  37.8MB/s    in 3.7s    \n","\n","2025-03-07 18:49:03 (31.7 MB/s) - ‘mRNA_miRNA_Meth_integrated.csv’ saved [123599052/123599052]\n","\n","Number of classes: 32\n","Number of samples: 8464\n","Number of Features: 2793\n"]}]},{"cell_type":"code","source":["# Step 9: Create PyTorch Geometric data object using the edge_index from the filtered PPI network\n","data = Data(x=X, edge_index=edge_index)\n","\n","# Step 10: Define the GTN model\n","class GTN(nn.Module):\n","    def __init__(self, num_features, num_classes, hidden_feats=1024, num_layers=2, dropout=0.5):\n","        super(GTN, self).__init__()\n","        self.convs = nn.ModuleList()\n","        self.convs.append(TransformerConv(num_features, hidden_feats, heads=1, dropout=dropout))\n","        for _ in range(num_layers - 1):\n","            self.convs.append(TransformerConv(hidden_feats, hidden_feats, heads=1, dropout=dropout))\n","        self.fc = nn.Linear(hidden_feats, num_classes)\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        for conv in self.convs:\n","            x = conv(x, edge_index)\n","            x = F.relu(x)\n","            x = self.dropout(x)\n","        x = self.fc(x)\n","        return F.log_softmax(x, dim=1)\n","\n","# Step 11: Set up K-fold cross-validation\n","k = 5\n","kf = KFold(n_splits=k, shuffle=True)\n","\n","# Initialize lists to store metrics for each fold\n","precision_scores = []\n","recall_scores = []\n","accuracy_scores = []\n","F1Measure = []\n","\n","# Set hyperparameters\n","hidden_feats = 1024\n","num_layers = 2\n","dropout = 0.5\n","lr = 0.001\n","weight_decay = 0\n","num_epochs = 100"],"metadata":{"id":"mIT3wokBenfm"},"id":"mIT3wokBenfm","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"0b18004c","metadata":{"id":"0b18004c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1741373419061,"user_tz":420,"elapsed":72316,"user":{"displayName":"Aleksandar Vakanski","userId":"07675307153279708378"}},"outputId":"049a9def-1fc5-4eee-ccb7-d236b8965c41"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training time: 0:01:12.276266\n"]}],"source":["# Step 12: Training and Evaluation\n","t = now()\n","for train_index, test_index in kf.split(X.cpu()):\n","    # Split the data into training and testing sets\n","    X_train, X_test = X[train_index], X[test_index]\n","    y_train, y_test = Y[train_index], Y[test_index]\n","\n","    # Create train/test data using the same PPI edge_index\n","    train_data = Data(x=X_train, edge_index=edge_index)\n","    test_data = Data(x=X_test, edge_index=edge_index)\n","\n","    # Create the GTN model\n","    model = GTN(\n","        num_features=X.shape[1],\n","        num_classes=len(set(Y.cpu().numpy())),\n","        hidden_feats=hidden_feats,\n","        num_layers=num_layers,\n","        dropout=dropout\n","    ).to(device)\n","    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","    scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=10)\n","    criterion = nn.NLLLoss()\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        optimizer.zero_grad()\n","        out = model(train_data)\n","        loss = criterion(out, y_train)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Validation\n","        model.eval()\n","        with torch.no_grad():\n","            logits = model(test_data)\n","            pred = torch.argmax(logits, dim=1)\n","            acc = accuracy_score(y_test.cpu().numpy(), pred.cpu().numpy())\n","            # print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}, Validation Accuracy: {acc:.4f}')\n","            scheduler.step(acc)\n","\n","    # Testing\n","    model.eval()\n","    with torch.no_grad():\n","        logits = model(test_data)\n","        pred = torch.argmax(logits, dim=1)\n","        test_acc = accuracy_score(y_test.cpu().numpy(), pred.cpu().numpy())\n","        precision = precision_score(y_test.cpu().numpy(), pred.cpu().numpy(), average='macro', zero_division=1)\n","        recall = recall_score(y_test.cpu().numpy(), pred.cpu().numpy(), average='macro')\n","        f1 = f1_score(y_test.cpu().numpy(), pred.cpu().numpy(), average='macro')\n","\n","        accuracy_scores.append(test_acc)\n","        precision_scores.append(precision)\n","        recall_scores.append(recall)\n","        F1Measure.append(f1)\n","print('Training time: %s' % (now() - t))"]},{"cell_type":"code","source":["# Calculate the average metrics across all folds\n","average_accuracy = np.mean(accuracy_scores)\n","average_precision = np.mean(precision_scores)\n","average_recall = np.mean(recall_scores)\n","average_f1 = np.mean(F1Measure)\n","\n","print(\"Average accuracy =\", average_accuracy)\n","print(\"Accuracy std sev =\", np.std(accuracy_scores))\n","print(\"Average precision =\", average_precision)\n","print(\"Precision std sev =\", np.std(precision_scores))\n","print(\"Average recall =\", average_recall)\n","print(\"Recall std sev =\", np.std(recall_scores))\n","print(\"Average F1 score =\", average_f1)\n","print(\"F1 std dev =\", np.std(F1Measure))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ISrYr9jHe80R","executionInfo":{"status":"ok","timestamp":1741373419068,"user_tz":420,"elapsed":8,"user":{"displayName":"Aleksandar Vakanski","userId":"07675307153279708378"}},"outputId":"2ada736a-8220-45b1-e094-0e84d0fa4fcd"},"id":"ISrYr9jHe80R","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Average accuracy = 0.9520330550354051\n","Accuracy std sev = 0.004433865609198085\n","Average precision = 0.9446092787639447\n","Precision std sev = 0.007422989624697369\n","Average recall = 0.9209231654365416\n","Recall std sev = 0.013145008384676457\n","Average F1 score = 0.9230865539887884\n","F1 std dev = 0.012157202620385159\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}